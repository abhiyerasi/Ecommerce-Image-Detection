{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run time Main Execute with Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  coco\n",
      "Dataset:  C:/abhilash/samples/idvscript\n",
      "Logs:  c:\\abhilash\\logs\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                17\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           idv\n",
      "NUM_CLASSES                    5\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                50\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights  c:\\abhilash\\mask_rcnn_coco.h5\n",
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: c:\\abhilash\\logs\\idv20180629T0652\\mask_rcnn_idv_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 337s 7s/step - loss: 1.3760 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.2278 - mrcnn_class_loss: 0.1382 - mrcnn_bbox_loss: 0.5367 - mrcnn_mask_loss: 0.4719 - val_loss: 1.1270 - val_rpn_class_loss: 0.0019 - val_rpn_bbox_loss: 0.3754 - val_mrcnn_class_loss: 0.1320 - val_mrcnn_bbox_loss: 0.3364 - val_mrcnn_mask_loss: 0.2813\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 323s 6s/step - loss: 0.6299 - rpn_class_loss: 8.6158e-04 - rpn_bbox_loss: 0.1723 - mrcnn_class_loss: 0.0691 - mrcnn_bbox_loss: 0.1934 - mrcnn_mask_loss: 0.1943 - val_loss: 0.6609 - val_rpn_class_loss: 0.0011 - val_rpn_bbox_loss: 0.2212 - val_mrcnn_class_loss: 0.0770 - val_mrcnn_bbox_loss: 0.1703 - val_mrcnn_mask_loss: 0.1913\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 318s 6s/step - loss: 0.4765 - rpn_class_loss: 8.5167e-04 - rpn_bbox_loss: 0.1551 - mrcnn_class_loss: 0.0530 - mrcnn_bbox_loss: 0.1277 - mrcnn_mask_loss: 0.1399 - val_loss: 0.7163 - val_rpn_class_loss: 9.2046e-04 - val_rpn_bbox_loss: 0.3234 - val_mrcnn_class_loss: 0.0829 - val_mrcnn_bbox_loss: 0.1568 - val_mrcnn_mask_loss: 0.1523\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 321s 6s/step - loss: 0.4625 - rpn_class_loss: 7.3400e-04 - rpn_bbox_loss: 0.1762 - mrcnn_class_loss: 0.0541 - mrcnn_bbox_loss: 0.1074 - mrcnn_mask_loss: 0.1240 - val_loss: 0.6151 - val_rpn_class_loss: 0.0018 - val_rpn_bbox_loss: 0.2283 - val_mrcnn_class_loss: 0.0776 - val_mrcnn_bbox_loss: 0.1670 - val_mrcnn_mask_loss: 0.1404\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 317s 6s/step - loss: 0.3636 - rpn_class_loss: 8.7517e-04 - rpn_bbox_loss: 0.1348 - mrcnn_class_loss: 0.0461 - mrcnn_bbox_loss: 0.0767 - mrcnn_mask_loss: 0.1052 - val_loss: 0.5604 - val_rpn_class_loss: 0.0018 - val_rpn_bbox_loss: 0.2747 - val_mrcnn_class_loss: 0.0538 - val_mrcnn_bbox_loss: 0.1130 - val_mrcnn_mask_loss: 0.1172\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 298s 6s/step - loss: 0.3141 - rpn_class_loss: 5.2791e-04 - rpn_bbox_loss: 0.0972 - mrcnn_class_loss: 0.0434 - mrcnn_bbox_loss: 0.0703 - mrcnn_mask_loss: 0.1027 - val_loss: 0.6049 - val_rpn_class_loss: 0.0013 - val_rpn_bbox_loss: 0.2650 - val_mrcnn_class_loss: 0.0839 - val_mrcnn_bbox_loss: 0.1448 - val_mrcnn_mask_loss: 0.1099\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 288s 6s/step - loss: 0.2870 - rpn_class_loss: 5.7967e-04 - rpn_bbox_loss: 0.1024 - mrcnn_class_loss: 0.0396 - mrcnn_bbox_loss: 0.0585 - mrcnn_mask_loss: 0.0859 - val_loss: 0.5366 - val_rpn_class_loss: 0.0016 - val_rpn_bbox_loss: 0.2334 - val_mrcnn_class_loss: 0.0614 - val_mrcnn_bbox_loss: 0.1389 - val_mrcnn_mask_loss: 0.1013\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 280s 6s/step - loss: 0.2391 - rpn_class_loss: 7.3449e-04 - rpn_bbox_loss: 0.0572 - mrcnn_class_loss: 0.0436 - mrcnn_bbox_loss: 0.0523 - mrcnn_mask_loss: 0.0853 - val_loss: 0.5686 - val_rpn_class_loss: 0.0012 - val_rpn_bbox_loss: 0.2950 - val_mrcnn_class_loss: 0.0630 - val_mrcnn_bbox_loss: 0.1096 - val_mrcnn_mask_loss: 0.0998\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 274s 5s/step - loss: 0.2458 - rpn_class_loss: 7.8347e-04 - rpn_bbox_loss: 0.0766 - mrcnn_class_loss: 0.0409 - mrcnn_bbox_loss: 0.0530 - mrcnn_mask_loss: 0.0745 - val_loss: 0.5441 - val_rpn_class_loss: 0.0017 - val_rpn_bbox_loss: 0.2678 - val_mrcnn_class_loss: 0.0798 - val_mrcnn_bbox_loss: 0.1037 - val_mrcnn_mask_loss: 0.0911\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 271s 5s/step - loss: 0.2662 - rpn_class_loss: 6.7729e-04 - rpn_bbox_loss: 0.0978 - mrcnn_class_loss: 0.0424 - mrcnn_bbox_loss: 0.0461 - mrcnn_mask_loss: 0.0793 - val_loss: 0.5307 - val_rpn_class_loss: 0.0011 - val_rpn_bbox_loss: 0.2686 - val_mrcnn_class_loss: 0.0693 - val_mrcnn_bbox_loss: 0.0987 - val_mrcnn_mask_loss: 0.0929\n",
      "Training network layers\n",
      "\n",
      "Starting at epoch 10. LR=0.001\n",
      "\n",
      "Checkpoint Path: c:\\abhilash\\logs\\idv20180629T0652\\mask_rcnn_idv_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "50/50 [==============================] - 329s 7s/step - loss: 0.2951 - rpn_class_loss: 8.7960e-04 - rpn_bbox_loss: 0.1395 - mrcnn_class_loss: 0.0432 - mrcnn_bbox_loss: 0.0392 - mrcnn_mask_loss: 0.0723 - val_loss: 0.5144 - val_rpn_class_loss: 0.0012 - val_rpn_bbox_loss: 0.2358 - val_mrcnn_class_loss: 0.0865 - val_mrcnn_bbox_loss: 0.1038 - val_mrcnn_mask_loss: 0.0870\n",
      "Epoch 12/15\n",
      "50/50 [==============================] - 308s 6s/step - loss: 0.2797 - rpn_class_loss: 5.4919e-04 - rpn_bbox_loss: 0.1305 - mrcnn_class_loss: 0.0401 - mrcnn_bbox_loss: 0.0417 - mrcnn_mask_loss: 0.0668 - val_loss: 0.5323 - val_rpn_class_loss: 0.0014 - val_rpn_bbox_loss: 0.3109 - val_mrcnn_class_loss: 0.0520 - val_mrcnn_bbox_loss: 0.0775 - val_mrcnn_mask_loss: 0.0905\n",
      "Epoch 13/15\n",
      "49/50 [============================>.] - ETA: 4s - loss: 0.2554 - rpn_class_loss: 7.6543e-04 - rpn_bbox_loss: 0.1106 - mrcnn_class_loss: 0.0364 - mrcnn_bbox_loss: 0.0436 - mrcnn_mask_loss: 0.0641"
     ]
    }
   ],
   "source": [
    "%run -i main.py train --dataset=C:/abhilash/samples/idvscript --weights=coco\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
